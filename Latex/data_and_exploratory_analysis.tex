% Data and Exploratory Analysis Section
\section{Data and Exploratory Analysis}

\subsection{Dataset Overview}

We consider two primary datasets for credit risk modeling: (i) the UCI Taiwan Credit Card Default dataset (30{,}000 samples; monthly billing/payment histories and demographics), and (ii) the Statlog (German) Credit dataset (1{,}000 samples; socio-economic attributes and loan characteristics). The German dataset serves as a compact, interpretable benchmark to validate generalization across data regimes and feature schemas. We follow the UCI conventions for feature definitions and target labeling (\(y=1\) indicates default; \(y=0\) non-default).

\paragraph{What is the German dataset about?} It contains borrower-level information at loan application time, with a binary risk label indicating ``good'' (non-default) or ``bad'' (default) credit. Attributes capture: (a) credit terms (duration, credit amount, installment rate), (b) financial standing (status of existing checking/savings accounts, employment length), and (c) personal/economic context (age, housing, job, dependents, telephone, foreign worker). Many predictors are categorical/ordinal codes reflecting risk-relevant categories used by lending institutions.

\paragraph{Attribute families.} For clarity, we group features into:
\begin{itemize}
    \item \textbf{Credit terms:} \emph{duration}, \emph{credit amount}, \emph{installment rate}, \emph{number of existing credits}.
    \item \textbf{Banking status:} \emph{checking account status}, \emph{savings account}, \emph{other installment plans}.
    \item \textbf{Demographics \/ socio-economics:} \emph{age}, \emph{employment length}, \emph{housing}, \emph{job}, \emph{telephone}, \emph{foreign worker}, \emph{personal status}.
    \item \textbf{Purpose \/ history:} \emph{credit history}, \emph{purpose} (e.g., car, furniture), and property-related indicators.
\end{itemize}

In our pipeline, we align label semantics across datasets (\(\texttt{default}=1\)), standardize naming, cap heavy-tailed numerics for robustness, and unify encodings (ordinal or one-hot as appropriate) to enable cross-dataset evaluation.

\subsection{Exploratory Data Analysis}

We summarize key findings from exploratory analysis of the German dataset and connect them to preprocessing choices.

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/germany_001.png}
        \caption{Class balance (default vs. non-default)}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/germany_002.png}
        \caption{Distribution of a key categorical attribute}
    \end{subfigure}
    \caption{Target distribution and categorical composition inform thresholding and encoding strategies. Class balance indicates the degree of imbalance to be handled during training and evaluation.}
    \label{fig:german_class_and_cats}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/germany_003.png}
        \caption{Credit amount distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/germany_004.png}
        \caption{Credit amount boxplot}
    \end{subfigure}
    \caption{Right-skew and outliers suggest winsorization/capping for numerical stability and to prevent tree-based models from over-partitioning extreme tails.}
    \label{fig:german_credit_amount}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/germany_005.png}
    \caption{Feature correlation/association matrix (numeric or encoded features). We observe modest associations among credit amount and duration, and weak pairwise associations among most categorical codes, implying limited multicollinearity after encoding.}
    \label{fig:german_corr}
\end{figure}

\paragraph{What is happening in the EDA, and why?} The EDA proceeds from univariate to bivariate analyses:
\begin{enumerate}
    \item \textbf{Class balance (Fig.~\ref{fig:german_class_and_cats}a).} We quantify the proportion of defaults vs. non-defaults to anticipate metric sensitivity and to guide threshold tuning or class-weighting.
    \item \textbf{Categorical composition (Fig.~\ref{fig:german_class_and_cats}b).} We inspect distributions of key categorical variables to detect sparse levels that may require grouping and to ensure encodings reflect ordinal structure where present (e.g., account status severity).
    \item \textbf{Numerical distributions (Fig.~\ref{fig:german_credit_amount}).} Histograms and boxplots reveal right-skew and outliers in \emph{credit amount} and related terms, motivating winsorization/capping to improve numerical stability and calibrate model sensitivity to extremes.
    \item \textbf{Correlation/association (Fig.~\ref{fig:german_corr}).} Heatmaps on numeric (and encoded) features identify correlated clusters (e.g., amount--duration) and generally low collinearity across categorical codes. This informs feature selection and regularization decisions.
    \item \textbf{Target-conditioned checks (not shown).} Where relevant, we examine class-conditional distributions (e.g., default vs. non-default credit amount) to identify features with discriminative power and to validate monotonic tendencies for rule design.
\end{enumerate}

\paragraph{Preprocessing implications.} Based on these observations, we (i) apply consistent categorical encoding with level consolidation where sparse, (ii) cap heavy-tailed numerical variables, (iii) harmonize labels and feature names across datasets, and (iv) retain a compact set of informative variables for cross-dataset comparability. These steps directly support robust training, better calibration, and improved interpretability of fuzzy rules and SHAP explanations in downstream modeling.

\paragraph{Reproducibility.} All EDA figures in this section are auto-extracted from the exploratory notebook (``Draft 1 Germany Dataset.ipynb''). The extraction script and figure paths are versioned within the repository to ensure repeatability.
